# Default values for ncps.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Global configuration
global:
  # Image registry override (if needed)
  imageRegistry: ""

# Number of replicas
# For HA mode, set to 2 or more
# For single instance, set to 1
# WARNING: If setting replicaCount > 1, you MUST also enable CDC (config.cdc.enabled: true)
# to prevent data corruption. See https://github.com/kalbasit/ncps/issues/660
replicaCount: 1

# Deployment mode: "deployment" or "statefulset"
# - deployment: For HA mode with S3 storage
# - statefulset: For single instance with local storage or HA with persistent state
mode: statefulset

image:
  # The image is also available at docker.io/kalbasit/ncps
  registry: ghcr.io
  repository: kalbasit/ncps
  pullPolicy: IfNotPresent
  # Overrides the image tag (default is chart appVersion)
  tag: ""

# Init image for directory creation (used for SQLite)
initImage:
  registry: docker.io
  repository: busybox
  tag: "1.37.0"
  pullPolicy: IfNotPresent
  # Resources for directory creation init container
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 32Mi
    # requests:
    #   cpu: 10m
    #   memory: 16Mi

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  # Automatically mount service account token
  automountServiceAccountToken: false

podSecurityContext:
  seccompProfile:
    type: RuntimeDefault
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  fsGroupChangePolicy: "OnRootMismatch"

securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true

config:
  # Anonymous usage statistics sent to the project maintainers.
  analytics:
    reporting:
      enabled: true

  # Cache hostname (REQUIRED)
  # Used for key generation and signing
  hostname: "ncps.example.com"

  # Logging level (trace, debug, info, warn, error, fatal, panic)
  logLevel: "info"

  # Server configuration
  server:
    # Listen address (format: :port or ip:port)
    addr: ":8501"

  # Cache permissions
  permissions:
    # Allow PUT verb to push narInfo and nar files directly
    allowPut: false
    # Allow DELETE verb to delete narInfo and nar files
    allowDelete: false

  # NAR info signing
  signing:
    # Whether to sign narInfo files
    enabled: true
    # Signing key (provided via secret if not auto-generated)
    # Leave empty to auto-generate
    secretKey: ""
    # Existing secret containing signing key
    # Key name must be "signing-key"
    existingSecret: ""

  # Cache size management
  cache:
    # Maximum cache size (with units: B, K, M, G, T)
    # Example: "100G", "5T"
    # Leave empty for unlimited
    maxSize: ""

    # LRU cleanup schedule (cron expression)
    # Example: "0 0 * * *" (daily at midnight)
    # Leave empty to disable
    lruSchedule: ""

    # Timezone for cron schedule
    # Example: "America/Los_Angeles", "UTC"
    lruTimezone: ""

    # Timeout for polling storage when waiting for download completion
    downloadPollTimeout: "30s"

    # Temporary directory for downloads
    # Mounted as emptyDir volume
    tempPath: "/tmp/ncps"

  # CDC (Content-Defined Chunking) configuration
  # Chunks are stored in the same backend as NAR files (different prefix/directory)
  cdc:
    # Enable CDC for deduplication (experimental)
    # REQUIRED for HA deployments (replicaCount > 1) to prevent timeouts and instability.
    # See https://github.com/kalbasit/ncps/issues/660
    enabled: false
    min: 16384
    avg: 65536
    max: 262144

    # Bypass flag for HA validation without CDC
    # Use with EXTREME CAUTION. Doing so may result in timeouts and instability.
    # See https://github.com/kalbasit/ncps/issues/660 for more details.
    iLoveTimeouts: false

  # Storage backend (choose ONE)
  storage:
    # Storage type: "local" or "s3"
    type: "local"

    # Local filesystem storage
    local:
      # Path for local storage
      path: "/storage"
      # Persistent volume configuration (only for local storage)
      persistence:
        enabled: true
        # Use existing PVC instead of creating a new one
        # When set, the chart will not create a PVC
        existingClaim: ""
        # Storage class (leave empty for default)
        storageClassName: ""
        accessModes:
          - ReadWriteOnce
        size: 20Gi
        # Annotations for PVC
        annotations: {}
        # Selector for specific PV
        selector: {}

    # S3-compatible storage
    s3:
      # S3 bucket name
      bucket: ""
      # S3 endpoint with scheme (e.g., https://s3.amazonaws.com or http://minio:9000)
      # The scheme (https:// or http://) determines SSL usage
      endpoint: ""
      # S3 region
      region: "us-east-1"
      # Force path-style S3 addressing (bucket/key vs key.bucket)
      # Required for MinIO, optional for AWS S3
      forcePathStyle: false
      # S3 credentials (provided via secret)
      accessKeyId: ""
      secretAccessKey: ""
      # Existing secret containing S3 credentials
      # Keys: "access-key-id" and "secret-access-key"
      existingSecret: ""

  # Database configuration
  database:
    # Database type: "sqlite", "postgresql", or "mysql"
    type: "sqlite"

    # SQLite configuration
    sqlite:
      # Path for SQLite database file
      path: "/storage/db/ncps.db"

    # PostgreSQL configuration
    postgresql:
      # Existing secret containing full PostgreSQL connection string
      # Secret must have a "database-url" key with the full connection string
      # Example: postgresql://user:password@host:port/database?sslmode=disable
      # Cannot be used together with any of the fields below
      existingSecret: ""

      # PostgreSQL connection details
      host: ""
      port: 5432
      database: "ncps"
      username: "ncps"
      # Password for PostgreSQL (chart builds connection string and stores in chart-managed secret)
      # Cannot be used together with existingSecret
      password: ""
      # SSL mode: disable, require, verify-ca, verify-full
      sslMode: "disable"
      # Additional connection parameters (e.g., "connect_timeout=10")
      # Only used when password is set (ignored when using existingSecret)
      extraParams: ""

    # MySQL configuration
    mysql:
      # Existing secret containing full MySQL connection string
      # Secret must have a "database-url" key with the full connection string
      # Example: mysql://user:password@host:port/database
      # Cannot be used together with any of the fields below
      existingSecret: ""

      # MySQL connection details
      host: ""
      port: 3306
      database: "ncps"
      username: "ncps"
      # Password for MySQL (chart builds connection string and stores in chart-managed secret)
      # Cannot be used together with existingSecret
      password: ""
      # Additional connection parameters (e.g., "timeout=10s")
      # Only used when password is set (ignored when using existingSecret)
      extraParams: ""

    # Connection pool settings
    pool:
      # Maximum open connections (0 = unlimited)
      # SQLite: always 1 (cannot be changed)
      # PostgreSQL/MySQL: default 25
      maxOpenConns: 0
      # Maximum idle connections
      # Default: 5 for PostgreSQL/MySQL
      maxIdleConns: 0

  # Upstream cache configuration
  upstream:
    # List of upstream caches
    caches:
      - url: "https://cache.nixos.org"
        publicKey: "cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY="

    # Connection timeouts
    dialerTimeout: "3s"
    responseHeaderTimeout: "3s"

    # Netrc file for authentication (optional)
    # Provided via secret if needed
    netrcFile: ""
    # Existing secret containing netrc file
    # Key name must be "netrc"
    existingNetrcSecret: ""

  # Redis configuration (for HA mode)
  redis:
    # Enable Redis distributed locking
    # Required for HA deployments with multiple replicas
    enabled: false

    # Redis connection
    addresses:
      - "redis:6379"

    # Authentication
    username: ""
    password: ""
    # Existing secret containing Redis credentials
    # Keys: "username" (optional) and "password"
    existingSecret: ""

    # Database number (0-15)
    db: 0

    # Use TLS
    useTLS: false

    # Connection pool size
    poolSize: 10

  # Lock configuration
  lock:
    # Lock backend to use: "local" or "redis"
    # - local: Single-instance mode (default)
    # - redis: Distributed mode using Redis (required if config.redis.enabled=true)
    backend: "local"

    # Redis-specific lock settings (only used when lock backend is redis)
    redis:
      # Key prefix for locks
      keyPrefix: "ncps:lock:"

    # Download lock TTL
    downloadTTL: "5m"
    # LRU lock TTL
    lruTTL: "30m"

    # Retry configuration
    retry:
      maxAttempts: 3
      initialDelay: "100ms"
      maxDelay: "2s"
      jitter: true

    # Degraded mode (emergency fallback)
    # WARNING: Breaks HA guarantees
    allowDegradedMode: false

  # Observability
  observability:
    # OpenTelemetry
    opentelemetry:
      enabled: false
      # gRPC collector URL
      # Examples:
      #   - http://otel-collector:4317 (insecure)
      #   - https://otel-collector:4317 (secure)
      #   - "" (stdout)
      grpcURL: ""

    # Prometheus metrics
    prometheus:
      enabled: false

service:
  type: ClusterIP
  port: 8501
  # Port name for service discovery
  portName: http
  annotations: {}
  # Session affinity for HA deployments
  # Options: None, ClientIP
  sessionAffinity: None

ingress:
  enabled: false
  className: "nginx"
  annotations: {}
    # cert-manager.io/cluster-issuer: "letsencrypt-prod"
    # nginx.ingress.kubernetes.io/proxy-body-size: "0"
  hosts:
    - host: ncps.example.com
      paths:
        - path: /
          pathType: Prefix
  tls: []
    # - secretName: ncps-tls
    #   hosts:
    #     - ncps.example.com

livenessProbe:
  httpGet:
    path: /healthz
    port: http
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /healthz
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

resources: {}
  # limits:
  #   cpu: 2000m
  #   memory: 2Gi
  # requests:
  #   cpu: 100m
  #   memory: 256Mi

podDisruptionBudget:
  enabled: false
  minAvailable: 1
  # maxUnavailable: 1

# Prometheus ServiceMonitor
serviceMonitor:
  enabled: false
  # Namespace for ServiceMonitor (defaults to release namespace)
  namespace: ""
  # Additional labels for ServiceMonitor
  labels: {}
  # Scrape interval
  interval: 30s
  # Scrape timeout
  scrapeTimeout: 10s

nodeSelector: {}

tolerations: []

affinity: {}
  # Example for HA anti-affinity:
  # podAntiAffinity:
  #   preferredDuringSchedulingIgnoredDuringExecution:
  #     - weight: 100
  #       podAffinityTerm:
  #         labelSelector:
  #           matchExpressions:
  #             - key: app.kubernetes.io/name
  #               operator: In
  #               values:
  #                 - ncps
  #         topologyKey: kubernetes.io/hostname

# Extra environment variables
extraEnvVars: []
  # - name: CUSTOM_VAR
  #   value: "custom-value"

# Extra volumes
extraVolumes: []

# Extra volume mounts
extraVolumeMounts: []

# Init containers
initContainers: []

# Sidecar containers
sidecars: []

# Database migration
migration:
  # Enable database migration
  enabled: true

  # Migration mode:
  # - "initContainer": Run as init container in each pod (default, safest)
  # - "job": Run as a Job with Helm hook (pre-install, pre-upgrade)
  # - "argocd": Run as a Job with ArgoCD pre-sync hook
  mode: "initContainer"

  # Resources for migration container/job
  resources: {}
    # limits:
    #   memory: 128Mi
    # requests:
    #   cpu: 50m
    #   memory: 64Mi

  # Security context for migration container/job
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000

  # Job configuration (only applies when mode is "job" or "argocd")
  job:
    # Backoff limit for job retries
    backoffLimit: 3

    # TTL after job finishes (in seconds)
    # Set to 0 to keep jobs indefinitely
    ttlSecondsAfterFinished: 300

    # Annotations for the job
    annotations: {}

    # Node selector for migration job
    nodeSelector: {}

    # Tolerations for migration job
    tolerations: []

    # Affinity for migration job
    affinity: {}

# FSCK (File System Consistency Check)
fsck:
  # Enable periodic fsck
  enabled: false

  # Schedule for fsck (cron expression)
  # Example: "0 1 * * *" (daily at 1 AM)
  schedule: "0 1 * * *"

  # Timezone for cron schedule. If empty, uses the cluster's default timezone.
  # Example: "America/Los_Angeles", "UTC"
  timezone: ""

  # Automatically repair issues
  repair: false

  # Skip checking NARs that have been verified within this duration
  # Examples: "24h", "1h"
  # Default is empty (verified-since will not be passed)
  verifiedSince: ""

  # Resources for fsck container/job
  resources: {}
    # limits:
    #   memory: 256Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # Security context for fsck container/job
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000

  # Job configuration
  job:
    # Concurrency policy for the job: "Allow", "Forbid" (default), or "Replace"
    concurrencyPolicy: Forbid

    # Backoff limit for job retries
    backoffLimit: 1

    # TTL after job finishes (in seconds)
    # Set to 0 to keep jobs indefinitely
    ttlSecondsAfterFinished: 3600

    # Annotations for the job
    annotations: {}

    # Node selector for fsck job
    nodeSelector: {}

    # Tolerations for fsck job
    tolerations: []

    # Affinity for fsck job
    affinity: {}

# Helm tests
# NOTE: Only enable when using `helm install`/`helm upgrade` with `helm test`
# When using `helm template` (manually or via tools like nixidy), keep disabled
# to prevent the test pod from being rendered as a regular resource
tests:
  enabled: false
